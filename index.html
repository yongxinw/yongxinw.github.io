<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'UA-7580334-2');
    </script>

    <title>Yongxin (Richard) Wang</title>

    <meta name="author" content="Yongxin Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="assets/images/cmu-scotty-scarf.png">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:top">
                        <p style="text-align:center">
                            <name>Yongxin (Richard) Wang</name>
                        </p>
                        <p>
                            I am an Applied Scientist at Amazon. I work on Amazon's suite of multimodal foundation models, with a focus on safety and alignment of generative models. We recently launched <a href="https://aws.amazon.com/bedrock/amazon-models/titan/" style="font-weight: bold;">Amazon Titan</a> (2023) and <a href="https://www.aboutamazon.com/news/aws/amazon-nova-artificial-intelligence-bedrock-aws" style="font-weight: bold;">Amazon Nova</a> (2024)
                            <s style="color:rgb(9, 111, 9)">I am currently an Applied Scientist at Amazon AutoGluon, working on an AutoML platform that allows users to train and eval ML models in just 3 lines of code.</s>
                            
                            <s style="color:blueviolet;">I am an Applied Scientist at Amazon AWS AI, under the Rekognition team providing image
                            analysis service to customers. I primaliry work on topics related to face recognition.</s>
                        </p>
                        <p>Prior to Amazon, I obtained my <a
                                href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-computer-vision/">Master
                            of Science in Computer Vision (MSCV)</a>
                            Degree at the <a href="https://www.ri.cmu.edu/">Robotics Insitute</a> of <a
                                    href="https://www.cmu.edu">Carnegie Mellon University</a>.</strike>  I work with
                            <a href="http://www.cs.cmu.edu/~kkitani/">Prof. Kris Kitani</a> on Multi-Object Tracking
                            (MOT), and <a href="https://www.cs.cmu.edu/~morency/">Prof. Louis-Philippe Morency</a>
                            on Multimodal Machine Learning. I obtained my Bachelor's Degrees from <a
                                    href="https://www.gatech.edu">Georgia Institute of Technology</a>
                            with double majors in Computer Science and Industrial Engineering. I also have worked with
                            <a href="http://www.rehg.org">Prof. Jim Rehg</a> on deep learning based human gaze analysis.
                        </p>
                        <p style="text-align:center">
                            yongxinw [at] amazon.com &nbsp/&nbsp
                            <a href="assets/bio/Yongxin_Wang_CV.pdf">CV</a> &nbsp/&nbsp
                            <a href="https://scholar.google.com/citations?user=VE02K0IAAAAJ">Google Scholar</a>
                            &nbsp/&nbsp
                            <a href="https://www.linkedin.com/in/yongxin-wang-944791a3/"> LinkedIn </a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="assets/bio/1733520453156.jpeg"><img style="width:100%;max-width:100%;border-radius:50%"
                                                                        alt="profile photo"
                                                                        src="assets/bio/1733520453156.jpeg"
                                                                        class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:top">
                        <heading>News</heading>
                        <li style="width:100%;vertical-align:top;padding-top: 20px;">
                            <strong>Nov. 2024</strong> - <a href="./assets/projects/nova/the-amazon-nova-family-of-models-technical-report-and-model-card.pdf">Amazon Nova Technical Report</a>.
                        </li>
                        <li>
                            <strong>Nov. 2024</strong> - <a href="https://www.aboutamazon.com/news/aws/amazon-nova-artificial-intelligence-bedrock-aws">Amazon Nova</a> is launched.
                        </li>
                        <li>
                            <strong>Jan. 2024</strong> - Patent granted for <a href="https://patents.google.com/patent/US11860977B1/en">Hierarchical graph neural networks for visual clustering</a>
                        </li>
                        <li>
                            <strong>Nov. 2023</strong> - <a href="https://aws.amazon.com/bedrock/amazon-models/titan/">Amazon Titan</a> is launched.
                        </li>
                        <li>
                            <strong>Oct. 2022</strong> - 2 papers accepted in ECCV 2022.
                        </li>
                        <li>
                            <strong>Oct. 2021</strong> - 1 paper accepted in ICCV 2021
                        </li>
                        <li>
                            <strong>Jun. 2021</strong> - 1 paper accepted in NAACL-HLT 2021
                        </li>
                        <li>
                            <strong>May. 2021</strong> - 1 paper accepted in ICRA 2021
                        </li>
                    </td>
                </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:top">
                        <heading>Publications</heading>
                        <!-- <p>
                            I'm interested in <strong>Computer Vision</strong>, <strong>Multimodal Machine
                            Learning</strong>, and <strong>Robotics</strong>. My research footprints have
                            covered Multi-Object Tracking (MOT), Multimodal Human Language Sequences, and human gaze
                            tracking.
                            I want to one day build a robot/agent that understands the intriguing human behaviors and
                            communicates naturally with humans.
                            I've also got some experience in data visualization.
                        </p> -->
                    </td>
                </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                    <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                        <td style="padding:20px;width:25%;vertical-align:top">
                            <div class="one">
                                <div class="two" id='socialIQ'><img src='assets/projects/nova/nova-s.png' style="width: 160px;"></div>
                                <!-- <img src='assets/projects/hilander/teaser.png'> -->
                            </div>
                            <script type="text/javascript">
                                function nightsight_start() {
                                    document.getElementById('nightsight_image').style.opacity = "1";
                                }
    
                                function nightsight_stop() {
                                    document.getElementById('nightsight_image').style.opacity = "0";
                                }
    
                                nightsight_stop()
                            </script>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:top">
                            <a href="assets/projects/nova/the-amazon-nova-family-of-models-technical-report-and-model-card.pdf">
                                <papertitle>The Amazon Nova family of models: Technical report and model card</papertitle>
                            </a>
                            
                            <br> Amazon Artificial General Intelligence, <em>2024</em>
                            <!-- <a href="https://github.com/jedyang97/MTAG">code</a> /
                            <a href="assets/projects/mtag/mtag.txt">bibtex</a> -->
                            <br>
                            <p></p>
                        </td>
                    </tr>

                <!-- SPE, ECCV 2021 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='socialIQ'><img src='assets/projects/spe/teaser.png' style="width: 160px;"></div>
                            <!-- <img src='assets/projects/hilander/teaser.png'> -->
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-19778-9_17">
                            <papertitle>Unsupervised and semi-supervised bias benchmarking in face recognition</papertitle>
                        </a>
                        <br>
                        Alexandra Chouldechova, Siqi Deng, <strong>Yongxin Wang</strong>, Wei Xia, Pietro Perona
                        <br>
                        <em>European Conference on Computer Vision (<strong>ECCV</strong>), 2022</em>
                        <br>
                        <!-- <a href="https://github.com/jedyang97/MTAG">code</a> /
                        <a href="assets/projects/mtag/mtag.txt">bibtex</a> -->
                        <br>
                        <p></p>
                    </td>
                </tr>

                <!-- PSS, ECCV 2021 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='socialIQ'><img src='assets/projects/pss/teaser.png' style="width: 160px;"></div>
                            <!-- <img src='assets/projects/hilander/teaser.png'> -->
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="https://link.springer.com/chapter/10.1007/978-3-031-19821-2_16">
                            <papertitle>PSS: Progressive Sample Selection for Open-World Visual Representation Learning</papertitle>
                        </a>
                        <br>
                        Tianyue Cao, <strong>Yongxin Wang</strong>, Yifan Xing, Tianjun Xiao, Tong He, Zheng Zhang, Hao Zhou, Joseph Tighe
                        <br>
                        <em>European Conference on Computer Vision (<strong>ECCV</strong>), 2022</em>
                        <br>
                        <!-- <a href="https://github.com/jedyang97/MTAG">code</a> /
                        <a href="assets/projects/mtag/mtag.txt">bibtex</a> -->
                        <br>
                        <p></p>
                    </td>
                </tr>

                <!-- Hilander, ICCV 2021 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='socialIQ'><img src='assets/projects/hilander/teaser.png' style="width: 160px;"></div>
                            <!-- <img src='assets/projects/hilander/teaser.png'> -->
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Xing_Learning_Hierarchical_Graph_Neural_Networks_for_Image_Clustering_ICCV_2021_paper.html">
                            <papertitle>Learning hierarchical graph neural networks for image clustering
                            </papertitle>
                        </a>
                        <br>
                        Yifan Xing, Tong He, Tianjun Xiao, <strong>Yongxin Wang</strong>, Yuanjun Xiong, Wei Xia, David Wipf, Zheng Zhang, Stefano Soatto
                        <br>
                        <em>International Conference on Computer Vision (<strong>ICCV</strong>), 2021</em>
                        <br>
                        <!-- <a href="https://github.com/jedyang97/MTAG">code</a> /
                        <a href="assets/projects/mtag/mtag.txt">bibtex</a> -->
                        <br>
                        <p></p>
                    </td>
                </tr>

                <!-- GNN Sentiment, NAACL-HLT 2021 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='socialIQ'><img src='assets/projects/mtag/teaser-1.png'></div>
                            <img src='assets/projects/mtag/teaser-1.png'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="assets/projects/mtag/MTAG_NAACL.pdf">
                            <papertitle>MTAG: Modal-Temporal Attention Graph for Unaligned Human Multimodal Language
                                Sequences
                            </papertitle>
                        </a>
                        <br>
                        <a href="https://jedyang.com/"> Jianing Yang*</a>,
                        <strong>Yongxin Wang*</strong>,
                        <a href="https://www.linkedin.com/in/ruitao-yi/">Ruitao Yi</a>,
                        <a href="https://www.linkedin.com/in/yuying-zhu-cmu/">Yuying Zhu</a>,
                        <a href="https://www.linkedin.com/in/azaanrehman/">Azaan Rehman</a>,
                        <a href="https://www.amir-zadeh.com/">Amir Zadeh</a>,
                        <a href="https://sporia.info/">Soujanya Poria</a>,
                        <a href="https://www.cs.cmu.edu/~morency/">Louis-Philippe Morency</a>
                        <br>
                        <em>Annual Conference of the North American Chapter of the Association for Computational
                            Linguistics (<strong>NAACL-HLT</strong>), 2021</em>
                        <br>
                        <a href="https://github.com/jedyang97/MTAG">code</a> /
                        <a href="assets/projects/mtag/mtag.txt">bibtex</a>
                        <br>
                        <p></p>
                        <p>Modal-Temporal Graph for analysing unaligned human language sequences. </p>
                        <p>(* indicates equal contribution)</p>
                    </td>
                </tr>

                <!-- GNN tracking, ICRA 2021 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='gnn_tracking'><img src='assets/projects/gsdt/gsdt.gif'></div>
                            <img src='assets/projects/gsdt/gsdt.gif'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }
                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="">
                            <papertitle>Joint Object Detection and Multi-Object Tracking with Graph Neural Networks</papertitle>
                        </a>
                        <br>
                        <strong>Yongxin Wang</strong>,
                        <a href="http://www.cs.cmu.edu/~kkitani/">Kris M. Kitani</a>,
                        <a href="http://www.xinshuoweng.com/">Xinshuo Weng</a>
                        <br>
                        <em>International Conference on Robotics and Automation (<strong>ICRA</strong>) 2021</em>
                        <br>
                        <a href="https://github.com/yongxinw/GSDT">code</a> /
                        <a href="https://www.xinshuoweng.com/projects/GSDT/">website</a> /
                        <a href="assets/projects/gsdt/slides.pdf">slides</a> /
                        <a href="assets/projects/gsdt/gsdt.txt">bibtex</a>
                        <br>
                        <p></p>
                        <p>Joint detection and association using Graph Neural Networks. Named GSDT on <a href="https://motchallenge.net/">MOTChallenge</a>. </p>
                    </td>
                </tr>


                <!-- GNN 3D Tracking, CVPR2020-->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='gnn3d'><img src='assets/projects/gnn3d/gnn3d.gif'></div>
                            <img src='assets/projects/gnn3d/gnn3d.gif'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="https://www.xinshuoweng.com/papers/GNN3DMOT/proceeding.pdf">
                            <papertitle>GNN3DMOT: Graph Neural Network for 3D Multi-Object Tracking with 2D-3D
                                Multi-Feature Learning
                            </papertitle>
                        </a>
                        <br>
                        <a href="http://www.xinshuoweng.com/">Xinshuo Weng</a>,
                        <strong>Yongxin Wang</strong>,
                        <a href="http://www.cs.cmu.edu/~kkitani/">Kris M. Kitani</a>
                        <br>
                        <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020</em>

                        <br>
                        <a href="https://github.com/xinshuoweng/GNN3DMOT">code</a> /
                        <a href="https://www.xinshuoweng.com/projects/GNN3DMOT/">website</a> /
                        <a href="assets/projects/gnn3d/slides.pdf">slides</a> /
                        <a href="assets/projects/gnn3d/bib.txt">bibtex</a>
                        <p>State-of-the-art performance in 3D MOT in KITTI dataset</p>
                    </td>
                </tr>

                <!-- Video gaze tracking, CVPR 2020 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='gaze2020'><img src='assets/projects/gaze_cvpr2020/VideoGaze2020.png'></div>
                            <img src='assets/projects/gaze_cvpr2020/VideoGaze2020.png'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="https://arxiv.org/pdf/2003.02501.pdf">
                            <papertitle>Detecting Attended Visual Targets in Video</papertitle>
                        </a>
                        <br>
                        <a href="https://www.cc.gatech.edu/~echong8/">Eunji Chong</a>,
                        <strong>Yongxin Wang</strong>,
                        <a href="https://natanielruiz.github.io/">Nataniel Ruiz </a>,
                        <a href="http://rehg.org/">James M. Rehg</a>
                        <br>
                        <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2020
                        <br>
                        <a href="https://github.com/ejcgt/attention-target-detection">code</a> /
                        <a href="https://github.com/ejcgt/attention-target-detection#dataset-1">dataset</a> /
                        <a href="assets/projects/gaze_cvpr2020/cvpr20bib.html">bibtex</a>
                        <p>Predicting where the people are looking at in videos.</p>
                    </td>
                </tr>

                <!-- Gaze tracking, ECCV 2018 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='nightsight_image'><img src='assets/projects/gaze_eccv2018/ECCV18_160x160.PNG'></div>
                            <img src='assets/projects/gaze_eccv2018/ECCV18_160x160.PNG'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Eunji_Chong_Connecting_Gaze_Scene_ECCV_2018_paper.pdf">
                            <papertitle>Connecting Gaze, Scene, and Attention:
                                Generalized Attention Estimation via Joint
                                Modeling of Gaze and Scene Saliency
                            </papertitle>
                        </a>
                        <br>
                        <a href="https://www.cc.gatech.edu/~echong8/">Eunji Chong</a>,
                        <a href="https://natanielruiz.github.io/">Nataniel Ruiz </a>,
                        <strong>Yongxin Wang</strong>,
                        <a href="https://sites.google.com/view/yunzhang/home">Yun Zhang</a>,
                        <a href="http://www.agatarozga.org/">Agata Rozga</a>,
                        <a href="http://rehg.org/">James M. Rehg</a>
                        <br>
                        <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2018
                        <br>
                        <a href="assets/projects/gaze_eccv2018/argos_poster.pdf">poster</a> /
                        <a href="assets/projects/gaze_eccv2018/Chong_2018_ECCV.txt">bibtex</a>
                        <br>
                        <p></p>
                        <p>Predicting where the people are looking at.</p>
                    </td>
                </tr>

                <!-- TypoTweet Maps, Euro Vis 2017 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='eurovis'><img src='assets/projects/typotweet/EuroVis17_160x160.PNG'></div>
                            <img src='assets/projects/typotweet/EuroVis17_160x160.PNG'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="assets/projects/typotweet/eurovis17-typotweet.pdf">
                            <papertitle>TypoTweet Maps: Characterizing Urban Areas
                                through Typographic Social Media Visualization
                            </papertitle>
                        </a>
                        <br>
                        <a href="http://www.jagodwin.com/">Alex Godwin</a>,
                        <strong>Yongxin Wang</strong>,
                        <a href="https://www.cc.gatech.edu/~john.stasko/">John T. Stasko</a>,
                        <br>
                        <em>European Conference on Visualization (<strong>EuroVis</strong>)</em>, 2017
                        <br>
                        <a href="assets/projects/typotweet/Godwin_2017_EuroViz.txt">bibtex</a>
                        <br>
                        <p></p>
                        <p>Visualizing social media data in a Typographic map.</p>
                    </td>
                </tr>


                </tbody>
            </table>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>Experiences</heading>
                    </td>
                </tr>
                </tbody>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
                <tbody>
                    
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:top">
                            <img src="assets/images/aws_160x160.png"></td>
                        <td width="75%" valign="top">
                            <a href="https://amazon.jobs/content/en/teams/AGI"><strong style="font-size: 18px">Amazon AGI</strong></a>, <strong style="font-size: 18px">Jun. 2023 - Present</strong>
                            <br>
                            <p>
                                Applied Scientist
                            </p>
                            <p>Launched <a href="https://aws.amazon.com/bedrock/amazon-models/titan/" style="font-weight: bold;">Amazon Titan</a> (2023) and <a href="https://www.aboutamazon.com/news/aws/amazon-nova-artificial-intelligence-bedrock-aws" style="font-weight: bold;">Amazon Nova</a> (2024) suites of foundation models, including Amazonâ€™s
                                large language models (LLMs), image generation models, and video generation models.</p>
                                <p>Responsible for R&D to improve the performance, safety, and transparency of generative AI models.</p>
                        </td>
                    </tr>
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:top">
                            <img src="assets/images/aws_160x160.png"></td>
                        <td width="75%" valign="top">
                            <a href="https://github.com/autogluon/autogluon"><strong style="font-size: 18px">Amazon AutoGluon</strong></a>, <strong style="font-size: 18px">Oct. 2022 - Jun. 2023</strong>
                            <br>
                            <p>
                                Applied Scientist
                            </p>
                            <p>Amazon's opensource AutoML Framekwork that allows users to train and evaluate ML models with 3 lines of code</p>
                        </td>
                    </tr>
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <img src="assets/images/aws_160x160.png"></td>
                    <td width="75%" valign="top">
                        <a href="https://aws.amazon.com/rekognition/"><strong style="font-size: 18px">Amazon
                            Rekognition</strong></a>, <strong style="font-size: 18px">Mar. 2020 - Oct. 2022</strong>
                        <br>
                        <p>
                            Applied Scientist
                        </p>
                        <p> Launched Celebrity Recognition V2 API. Launched Face Embedding Model V6</p>
                    </td>
                </tr>
                <!-- Kris -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:top"><img
                            src="assets/images/cmu-wordmark-square-w-on-r_160x160.png"></td>
                    <td width="75%" valign="top">
                        <a href="http://www.cmu.edu"><strong style="font-size: 18px">Carnegie Mellon University</strong></a>,
                        <strong style="font-size: 18px">Jan. 2019 - Mar. 2020</strong>
                        <br>
                        <p>
                            Research Assistant with <a href="http://www.cs.cmu.edu/~kkitani/"><strong>Prof. Kris
                            Kitani</strong></a>
                        </p>
                        <p> Worked on simultaneous detection and associate with Graph Neural Networks for Multi-Object
                            Tracking</p>
                    </td>
                </tr>
                <!-- LP -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <img src="assets/images/cmu-wordmark-square-w-on-r_160x160.png"></td>
                    <td width="75%" valign="top">
                        <a href="http://www.cmu.edu"><strong style="font-size: 18px">Carnegie Mellon University</strong></a>,
                        <strong style="font-size: 18px">Aug. 2019 - Mar. 2020</strong>
                        <br>
                        <p>
                            Research Assistant with <a href="https://www.cs.cmu.edu/~morency/"><strong>Prof.
                            Louis-Philippe Morency</strong></a>
                        </p>
                        <p> Worked on modeling multimodal temporal languange sequences with Graph Neural Networks</p>
                    </td>
                </tr>
                <!-- Amazon -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <img src="assets/images/aws_160x160.png"></td>
                    <td width="75%" valign="top">
                        <a href="https://aws.amazon.com/rekognition/"><strong style="font-size: 18px">Amazon
                            Rekognition</strong></a>, <strong style="font-size: 18px">May. 2019 - Aug. 2019</strong>
                        <br>
                        <p>
                            Applied Scientist Intern with <a
                                href="https://scholar.google.se/citations?user=OCdJxC8AAAAJ"><strong>Dr. Wei
                            Xia</strong></a>
                        </p>
                        <p> Worked on high-resolution face synthesis with disentangled control through facial identity
                            and attributes</p>
                    </td>
                </tr>
                <!-- GT -->
                <tr>
                    <td style="width:25%;vertical-align:top;horiz-align: right">
                        <img src="assets/images/gt_160x160.png" style="horiz-align: right"></td>
                    <td width="75%" style="vertical-align:top">
                        <p><a href="http://www.gatech.edu"><strong style="font-size: 18px">Georgia Institute of
                            Technology</strong></a>, <strong style="font-size: 18px">Jan. 2017 - May. 2018</strong></p>
                        <p>
                            Research Assistant Intern with <a href="https://www.rehg.org"><strong>Prof. Jim
                            Rehg</strong></a>
                        </p>
                        <p> Worked on gaze target prediction in image and in video</p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            Template from <a href="https://jonbarron.info/">here</a>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>

</html>
