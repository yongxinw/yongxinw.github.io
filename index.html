<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'UA-7580334-2');
    </script>

    <title>Yongxin (Richard) Wang</title>

    <meta name="author" content="Yongxin Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="assets/images/cmu-scotty-scarf.png">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:top">
                        <p style="text-align:center">
                            <name>Yongxin (Richard) Wang</name>
                        </p>
                        <p>I am an Applied Scientist at Amazon AWS AI, under the Rekognition team providing image
                            analysis service to customers. I primaliry work on topics related to face recognition.
                        </p>
                        <p>Prior to Amazon, I obtained my <a
                                href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-computer-vision/">Master
                            of Science in Computer Vision (MSCV)</a>
                            Degree at the <a href="https://www.ri.cmu.edu/">Robotics Insitute</a> of <a
                                    href="https://www.cmu.edu">Carnegie Mellon University</a>.</strike>  I work with
                            <a href="http://www.cs.cmu.edu/~kkitani/">Prof. Kris Kitani</a> on Multi-Object Tracking
                            (MOT), and <a href="https://www.cs.cmu.edu/~morency/">Prof. Louis-Philippe Morency</a>
                            on Multimodal Machine Learning (MMML). I obtained my Bachelor's Degrees from <a
                                    href="https://www.gatech.edu">Georgia Institute of Technology</a>
                            with double majors in Computer Science and Industrial Engineering. I also have worked with
                            <a href="http://www.rehg.org">Prof. Jim Rehg</a> on deep learning based human gaze analysis.
                        </p>
                        <p style="text-align:center">
                            <a href="mailto:yongxinw@cs.cmu.edu">yongxinw@cs.cmu.edu</a> &nbsp/&nbsp
                            <a href="assets/bio/Yongxin_Wang_CV_20200428.pdf">CV</a> &nbsp/&nbsp
                            <a href="https://scholar.google.com/citations?user=VE02K0IAAAAJ">Google Scholar</a>
                            &nbsp/&nbsp
                            <a href="https://www.linkedin.com/in/yongxin-wang-944791a3/"> LinkedIn </a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="assets/bio/HEADSHOT_RICHARD.jpeg"><img style="width:100%;max-width:100%"
                                                                        alt="profile photo"
                                                                        src="assets/bio/HEADSHOT_RICHARD_circle.png"
                                                                        class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:top">
                        <heading>Research</heading>
                        <p>
                            I'm interested in <strong>Computer Vision</strong>, <strong>Multimodal Machine
                            Learning</strong>, and <strong>Robotics</strong>. My research footprints have
                            covered Multi-Object Tracking (MOT), Multimodal Human Language Sequences, and human gaze
                            tracking.
                            I want to one day build a robot/agent that understands the intriguing human behaviors and
                            communicates naturally with humans.
                            I've also got some experience in data visualization.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>

                <!-- GNN Sentiment, NAACL-HLT 2021 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='socialIQ'><img src='assets/projects/mtag/teaser-1.png'></div>
                            <img src='assets/projects/mtag/teaser-1.png'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="assets/projects/mtag/MTAG_NAACL.pdf">
                            <papertitle>MTAG: Modal-Temporal Attention Graph for Unaligned Human Multimodal Language
                                Sequences
                            </papertitle>
                        </a>
                        <br>
                        <a href="https://jedyang.com/"> Jianing Yang*</a>,
                        <strong>Yongxin Wang*</strong>,
                        <a href="https://www.linkedin.com/in/ruitao-yi/">Ruitao Yi</a>,
                        <a href="https://www.linkedin.com/in/yuying-zhu-cmu/">Yuying Zhu</a>,
                        <a href="https://www.linkedin.com/in/azaanrehman/">Azaan Rehman</a>,
                        <a href="https://www.amir-zadeh.com/">Amir Zadeh</a>,
                        <a href="https://sporia.info/">Soujanya Poria</a>,
                        <a href="https://www.cs.cmu.edu/~morency/">Louis-Philippe Morency</a>
                        <br>
                        <em>Annual Conference of the North American Chapter of the Association for Computational
                            Linguistics (<strong>NAACL-HLT</strong>), 2021</em>
                        <br>
                        <a href="https://github.com/jedyang97/MTAG">code</a> /
                        <a href="https://www.xinshuoweng.com/projects/GSDT/">website</a> /
                        <a href="assets/projects/gsdt/slides.pdf">slides</a> /
                        <a href="assets/projects/gsdt/gsdt.txt">bibtex</a>
                        <br>
                        <p></p>
                        <p>Modal-Temporal Graph for analysing unaligned human language sequences. </p>
                        <p>(* indicates equal contribution)</p>
                    </td>
                </tr>

                <!-- GNN tracking, ICRA 2021 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='gnn_tracking'><img src='assets/projects/gsdt/gsdt.gif'></div>
                            <img src='assets/projects/gsdt/gsdt.gif'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }
                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="">
                            <papertitle>Joint Object Detection and Multi-Object Tracking with Graph Neural Networks</papertitle>
                        </a>
                        <br>
                        <strong>Yongxin Wang</strong>,
                        <a href="http://www.cs.cmu.edu/~kkitani/">Kris M. Kitani</a>,
                        <a href="http://www.xinshuoweng.com/">Xinshuo Weng</a>
                        <br>
                        <em>International Conference on Robotics and Automation (<strong>ICRA</strong>) 2021</em>
                        <br>
                        <a href="https://github.com/yongxinw/GSDT">code</a> /
                        <a href="https://www.xinshuoweng.com/projects/GSDT/">website</a> /
                        <a href="assets/projects/gsdt/slides.pdf">slides</a> /
                        <a href="assets/projects/gsdt/gsdt.txt">bibtex</a>
                        <br>
                        <p></p>
                        <p>Joint detection and association using Graph Neural Networks. Named GSDT on <a href="https://motchallenge.net/">MOTChallenge</a>. </p>
                    </td>
                </tr>


                <!-- GNN 3D Tracking, CVPR2020-->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='gnn3d'><img src='assets/projects/gnn3d/gnn3d.gif'></div>
                            <img src='assets/projects/gnn3d/gnn3d.gif'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="https://www.xinshuoweng.com/papers/GNN3DMOT/proceeding.pdf">
                            <papertitle>GNN3DMOT: Graph Neural Network for 3D Multi-Object Tracking with 2D-3D
                                Multi-Feature Learning
                            </papertitle>
                        </a>
                        <br>
                        <a href="http://www.xinshuoweng.com/">Xinshuo Weng</a>,
                        <strong>Yongxin Wang</strong>,
                        <a href="http://www.cs.cmu.edu/~kkitani/">Kris M. Kitani</a>
                        <br>
                        <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2020</em>

                        <br>
                        <a href="https://github.com/xinshuoweng/GNN3DMOT">code</a> /
                        <a href="https://www.xinshuoweng.com/projects/GNN3DMOT/">website</a> /
                        <a href="assets/projects/gnn3d/slides.pdf">slides</a> /
                        <a href="assets/projects/gnn3d/bib.txt">bibtex</a>
                        <p>State-of-the-art performance in 3D MOT in KITTI dataset</p>
                    </td>
                </tr>

                <!-- Video gaze tracking, CVPR 2020 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='gaze2020'><img src='assets/projects/gaze_cvpr2020/VideoGaze2020.png'></div>
                            <img src='assets/projects/gaze_cvpr2020/VideoGaze2020.png'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="https://arxiv.org/pdf/2003.02501.pdf">
                            <papertitle>Detecting Attended Visual Targets in Video</papertitle>
                        </a>
                        <br>
                        <a href="https://www.cc.gatech.edu/~echong8/">Eunji Chong</a>,
                        <strong>Yongxin Wang</strong>,
                        <a href="https://natanielruiz.github.io/">Nataniel Ruiz </a>,
                        <a href="http://rehg.org/">James M. Rehg</a>
                        <br>
                        <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2020
                        <br>
                        <a href="https://github.com/ejcgt/attention-target-detection">code</a> /
                        <a href="https://github.com/ejcgt/attention-target-detection#dataset-1">dataset</a> /
                        <a href="assets/projects/gaze_cvpr2020/cvpr20bib.html">bibtex</a>
                        <p>Predicting where the people are looking at in videos.</p>
                    </td>
                </tr>

                <!-- Gaze tracking, ECCV 2018 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='nightsight_image'><img src='assets/projects/gaze_eccv2018/ECCV18_160x160.PNG'></div>
                            <img src='assets/projects/gaze_eccv2018/ECCV18_160x160.PNG'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Eunji_Chong_Connecting_Gaze_Scene_ECCV_2018_paper.pdf">
                            <papertitle>Connecting Gaze, Scene, and Attention:
                                Generalized Attention Estimation via Joint
                                Modeling of Gaze and Scene Saliency
                            </papertitle>
                        </a>
                        <br>
                        <a href="https://www.cc.gatech.edu/~echong8/">Eunji Chong</a>,
                        <a href="https://natanielruiz.github.io/">Nataniel Ruiz </a>,
                        <strong>Yongxin Wang</strong>,
                        <a href="https://sites.google.com/view/yunzhang/home">Yun Zhang</a>,
                        <a href="http://www.agatarozga.org/">Agata Rozga</a>,
                        <a href="http://rehg.org/">James M. Rehg</a>
                        <br>
                        <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2018
                        <br>
                        <a href="assets/projects/gaze_eccv2018/argos_poster.pdf">poster</a> /
                        <a href="assets/projects/gaze_eccv2018/Chong_2018_ECCV.txt">bibtex</a>
                        <br>
                        <p></p>
                        <p>Predicting where the people are looking at.</p>
                    </td>
                </tr>

                <!-- TypoTweet Maps, Euro Vis 2017 -->
                <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <div class="one">
                            <div class="two" id='eurovis'><img src='assets/projects/typotweet/EuroVis17_160x160.PNG'></div>
                            <img src='assets/projects/typotweet/EuroVis17_160x160.PNG'>
                        </div>
                        <script type="text/javascript">
                            function nightsight_start() {
                                document.getElementById('nightsight_image').style.opacity = "1";
                            }

                            function nightsight_stop() {
                                document.getElementById('nightsight_image').style.opacity = "0";
                            }

                            nightsight_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <a href="assets/projects/typotweet/eurovis17-typotweet.pdf">
                            <papertitle>TypoTweet Maps: Characterizing Urban Areas
                                through Typographic Social Media Visualization
                            </papertitle>
                        </a>
                        <br>
                        <a href="http://www.jagodwin.com/">Alex Godwin</a>,
                        <strong>Yongxin Wang</strong>,
                        <a href="https://www.cc.gatech.edu/~john.stasko/">John T. Stasko</a>,
                        <br>
                        <em>European Conference on Visualization (<strong>EuroVis</strong>)</em>, 2017
                        <br>
                        <a href="assets/projects/typotweet/Godwin_2017_EuroViz.txt">bibtex</a>
                        <br>
                        <p></p>
                        <p>Visualizing social media data in a Typographic map.</p>
                    </td>
                </tr>


                </tbody>
            </table>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>Experiences</heading>
                    </td>
                </tr>
                </tbody>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
                <tbody>
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <img src="assets/images/aws_160x160.png"></td>
                    <td width="75%" valign="top">
                        <a href="https://aws.amazon.com/rekognition/"><strong style="font-size: 18px">Amazon
                            Rekognition</strong></a>, <strong style="font-size: 18px">Mar. 2020 - Present</strong>
                        <br>
                        <p>
                            Applied Scientist
                        </p>
                        <p> Working on face recognition services and technologies.</p>
                    </td>
                </tr>
                <!-- Kris -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:top"><img
                            src="assets/images/cmu-wordmark-square-w-on-r_160x160.png"></td>
                    <td width="75%" valign="top">
                        <a href="http://www.cmu.edu"><strong style="font-size: 18px">Carnegie Mellon University</strong></a>,
                        <strong style="font-size: 18px">Jan. 2019 - Present</strong>
                        <br>
                        <p>
                            Research Assistant with <a href="http://www.cs.cmu.edu/~kkitani/"><strong>Prof. Kris
                            Kitani</strong></a>
                        </p>
                        <p> Worked on simultaneous detection and associate with Graph Neural Networks for Multi-Object
                            Tracking</p>
                    </td>
                </tr>
                <!-- LP -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <img src="assets/images/cmu-wordmark-square-w-on-r_160x160.png"></td>
                    <td width="75%" valign="top">
                        <a href="http://www.cmu.edu"><strong style="font-size: 18px">Carnegie Mellon University</strong></a>,
                        <strong style="font-size: 18px">Aug. 2019 - Present</strong>
                        <br>
                        <p>
                            Research Assistant with <a href="https://www.cs.cmu.edu/~morency/"><strong>Prof.
                            Louis-Philippe Morency</strong></a>
                        </p>
                        <p> Worked on modeling multimodal temporal languange sequences with Graph Neural Networks</p>
                    </td>
                </tr>
                <!-- Amazon -->
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:top">
                        <img src="assets/images/aws_160x160.png"></td>
                    <td width="75%" valign="top">
                        <a href="https://aws.amazon.com/rekognition/"><strong style="font-size: 18px">Amazon
                            Rekognition</strong></a>, <strong style="font-size: 18px">May. 2019 - Aug. 2019</strong>
                        <br>
                        <p>
                            Applied Scientist Intern with <a
                                href="https://scholar.google.se/citations?user=OCdJxC8AAAAJ"><strong>Dr. Wei
                            Xia</strong></a>
                        </p>
                        <p> Worked on high-resolution face synthesis with disentangled control through facial identity
                            and attributes</p>
                    </td>
                </tr>
                <!-- GT -->
                <tr>
                    <td style="width:25%;vertical-align:top;horiz-align: right">
                        <img src="assets/images/gt_160x160.png" style="horiz-align: right"></td>
                    <td width="75%" style="vertical-align:top">
                        <p><a href="http://www.gatech.edu"><strong style="font-size: 18px">Georgia Institute of
                            Technology</strong></a>, <strong style="font-size: 18px">Jan. 2017 - May. 2018</strong></p>
                        <p>
                            Research Assistant Intern with <a href="https://www.rehg.org"><strong>Prof. Jim
                            Rehg</strong></a>
                        </p>
                        <p> Worked on gaze target prediction in image and in video</p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            Template from <a href="https://jonbarron.info/">here</a>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>

</html>
